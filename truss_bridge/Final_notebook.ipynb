{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project CEGM2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import numpy.random as rnd\n",
    "\n",
    "#sys.path.append(r'C:\\Users\\javie\\OneDrive - Delft University of Technology\\Year 2\\Q2\\CEGM2003 - Data Science and Artificial Inteligence for engineers\\!Content\\Unit 0 - Project\\TRUSS1\\pyJive')\n",
    "sys.path.append('../pyJive/')\n",
    "\n",
    "from utils import proputils as pu\n",
    "import main\n",
    "from names import GlobNames as gn\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom_file(y_list): \n",
    "    \n",
    "    file = open('bridge.geom')\n",
    "    filestring = file.read()\n",
    "\n",
    "    split = filestring.split('\\n')\n",
    "\n",
    "    y_list = np.append(y_list, y_list[:-1][::-1])\n",
    "    mod_indices = np.arange(3,20,2)\n",
    "\n",
    "    count =     0\n",
    "    for i in range(len(split)):\n",
    "        split[i] += '\\n'\n",
    "        if i in mod_indices:\n",
    "            linesplit = split[i].split(' ')\n",
    "            linesplit[-1] = str(y_list[count]) + '\\n'\n",
    "            split[i] = ' '.join(linesplit)\n",
    "            count += 1\n",
    "\n",
    "    geom = ' '.join(split)\n",
    "\n",
    "    with open(\"geomfile.geom\", \"w\") as file:\n",
    "        file.write(geom)\n",
    "        \n",
    "    return file.name\n",
    "\n",
    "def eigenfrequencies(A_list, y_list):\n",
    "\n",
    "    # Read the input file and store in props object\n",
    "    props = pu.parse_file('bridge_frequency.pro')\n",
    "    props['model']['truss']['area'] = A_list\n",
    "    props['init']['mesh']['file'] = get_geom_file(y_list)\n",
    "    \n",
    "    \n",
    "    # Call the program and store output in globdat\n",
    "    globdat = main.jive(props)\n",
    "\n",
    "    # Write additional output\n",
    "    return(globdat[gn.EIGENFREQS][0:3]/2/np.pi)\n",
    "\n",
    "def constraint(A_list, y_list, constr1=20, constr2=40, constr3=60):\n",
    "    \n",
    "    # convert first three natrual frequencies to Hz\n",
    "    freq1, freq2, freq3 = eigenfrequencies(A_list, y_list)\n",
    "    \n",
    "    # calculate the violations of the constraints\n",
    "    violation1 = max(0, constr1 - freq1)\n",
    "    violation2 = max(0, constr2 - freq2)\n",
    "    violation3 = max(0, constr3 - freq3)\n",
    "    \n",
    "    #calculate the losses with the penalty\n",
    "    total_violation = violation1 + violation2 + violation3\n",
    "    return total_violation\n",
    "\n",
    "def mass_TRUSS(Areas, y_list, density=7800):\n",
    "    \n",
    "    x_coordinates=[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10]\n",
    "    y_coordinates = [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "    y_coordinates[2] = y_list[0]\n",
    "    y_coordinates[4] = y_list[1]\n",
    "    y_coordinates[6] = y_list[2]\n",
    "    y_coordinates[8] = y_list[3]\n",
    "    y_coordinates[10] = y_list[4]\n",
    "    y_coordinates[12] = y_list[3]\n",
    "    y_coordinates[14] = y_list[2]\n",
    "    y_coordinates[16] = y_list[1]\n",
    "    y_coordinates[18] = y_list[0]\n",
    "    \n",
    "    #Calculate the lengths of the different elements\n",
    "    Lengths = np.zeros(len(Areas))\n",
    "    \n",
    "    \n",
    "    Lengths[0] = 1\n",
    "    Lengths[1] = np.sqrt(x_coordinates[2]**2 + y_coordinates[2]**2)\n",
    "    Lengths[2] = y_coordinates[2]\n",
    "    Lengths[3] = np.sqrt((x_coordinates[2]-x_coordinates[3])**2 + (y_coordinates[2]-y_coordinates[3])**2)\n",
    "    Lengths[4] = np.sqrt(1 + (y_coordinates[2]-y_coordinates[4])**2)\n",
    "    Lengths[5] = y_coordinates[4]\n",
    "    Lengths[6] = np.sqrt((x_coordinates[4]-x_coordinates[5])**2 + (y_coordinates[4]-y_coordinates[5])**2)\n",
    "    Lengths[7] = np.sqrt(1 + (y_coordinates[4]-y_coordinates[6])**2)\n",
    "    Lengths[8] = y_coordinates[6]\n",
    "    Lengths[9] = np.sqrt((x_coordinates[6]-x_coordinates[7])**2 + (y_coordinates[6]-y_coordinates[7])**2)\n",
    "    Lengths[10] = np.sqrt(1 + (y_coordinates[6]-y_coordinates[8])**2)\n",
    "    Lengths[11] = y_coordinates[8]\n",
    "    Lengths[12] = np.sqrt((x_coordinates[8]-x_coordinates[9])**2 + (y_coordinates[8]-y_coordinates[9])**2)\n",
    "    Lengths[13] = np.sqrt(1 + (y_coordinates[8]-y_coordinates[10])**2)\n",
    "    Lengths[14] = y_coordinates[10]\n",
    "    \n",
    "    #Calculate the volumes of the elements\n",
    "    Volumes = Lengths * Areas\n",
    "    \n",
    "    #Calculate the total volume by summing the elements\n",
    "    Total_Volume = 10*Volumes[0] + 2*(Volumes[1] + Volumes[2] + Volumes[3] + Volumes[4] + Volumes[5] + Volumes[6] + Volumes[7] + Volumes[9] + Volumes[10] + Volumes[11] + Volumes[12] + Volumes[13]) + Volumes[14]\n",
    "    \n",
    "    #Calculate the total mass\n",
    "    Mass = Total_Volume * density\n",
    "    \n",
    "    return Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(A_list, y_list, mass_penalty=1, constraint_penalty=1000000):\n",
    "    total_loss = (constraint_penalty * constraint(A_list, y_list)) + (mass_penalty * mass_TRUSS(A_list, y_list))\n",
    "    if constraint(A_list, y_list) != 0:\n",
    "        print(f'The constraints for the natural frequencies are not met')\n",
    "    else:\n",
    "        print(f'The constraints of the natural frequencies are met')\n",
    "        \n",
    "    return print(f'The total loss is:{total_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = 0.008\n",
    "A_list_init = 0.005 * np.ones(15)\n",
    "y_list_init = [1,1,1,1,1]\n",
    "A_list_random = mx * (rnd.random_sample(size=15))         #length must be 15\n",
    "y_list_random = np.arange(1,6,1)\n",
    "\n",
    "A_list_kanarachos = [ 40e-4, 3.1997e-4, 1.0025e-4, 1.0000e-4, 2.5875e-4, 1.0895e-4, 1.1261e-4, 2.5624e-4, 1.4121e-4, 1.5758e-4, 2.2461e-4, 1.0694e-4, 1.3193e-4, 2.3846e-4, 1.0001e-4 ]\n",
    "\n",
    "y_list_kanarachos = [1.0108, 1.3860, 1.5608, 1.6802, 1.7580]\n",
    "\n",
    "# loss_init = loss_function(A_list_init, y_list_init)\n",
    "# loss = loss_function(A_list_random, y_list_random)\n",
    "loss_karnacharos= loss_function(A_list_kanarachos, y_list_kanarachos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
